{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN575GR4JdxfXRXIsI3knsW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pswami12/DataScienceFiles/blob/main/Class_3_AIDL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FuL_KYFNUD8B"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "V0 = torch.tensor(1.3)\n",
        "V1 = torch.tensor([1.,2.,3.])\n",
        "V2 = torch.tensor([[1.,2.],[4.,5.]])\n",
        "print(f'{V0}, {V1}, {V2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLSohTWYdlpi",
        "outputId": "f1208d4f-e676-4696-a9ae-0d4390d15322"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.2999999523162842, tensor([1., 2., 3.]), tensor([[1., 2.],\n",
            "        [4., 5.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "V0 = np.array(1.3)\n",
        "V1 = np.array([1.,2.,3.])\n",
        "V2 = np.array([[1.,2.],[4.,5.]])\n",
        "print(f'{V0}, {V1}, {V2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ei6Rbhagnih",
        "outputId": "916f6e94-e2ae-41ec-beee-1d01ac62bf7f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.3, [1. 2. 3.], [[1. 2.]\n",
            " [4. 5.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numpy_array = np.array([1,2,3])\n",
        "numpy_array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBek9vugg1hv",
        "outputId": "b00db1eb-cd76-4519-e779-660fe0875911"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.Tensor(numpy_array)\n",
        "t1\n",
        "#Constructor - same as torch.FloatTensor\n",
        "#Uses a default float32 tensor, can be changed\n",
        "#all other tensor inherits from this main tensor class\n",
        "#torch.tensor(data, dtype=None, device=None, requires_grad =False) -> Tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7L3w9Bp1g_1r",
        "outputId": "7d6a9dcc-6d36-4d4f-8afa-76324f392463"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t2 = torch.tensor(numpy_array)\n",
        "t2\n",
        "#Factory function\n",
        "#produces a new tensor with same type\n",
        "#does not share underlying memory with numpy\n",
        "#always copies the data\n",
        "#torch.tensor(x) is equivalent to x.clone().detach()\n",
        "#recommend to use"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luPasjE7hG3z",
        "outputId": "42cde968-43dc-4020-a2be-a35786ede3df"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t3 = torch.as_tensor(numpy_array)\n",
        "t3\n",
        "#produce a new tensor with same dtype\n",
        "#share underlying memory with numpy, changing one will change other\n",
        "#can accepts any array like python data structure"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TszkunFQhNj-",
        "outputId": "5cc2e011-0694-4a63-ae3c-1196b823bbfa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t4 = torch.from_numpy(numpy_array)\n",
        "t4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHNTPo7Vhi7C",
        "outputId": "fb1feb48-21de-4c09-ed13-58d7c6e686e3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}